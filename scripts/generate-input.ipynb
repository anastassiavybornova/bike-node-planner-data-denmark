{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: script description\n",
    "\n",
    "Script that \n",
    "* takes as input the files config-layers-X (X: polygon, point, linestring), and municipality codes\n",
    "* for all municipality codes jointly, fetches the *raw* data from GeoFA and makes a *processed* network (`network/raw/` and `network/processed/`)\n",
    "* for each X,\n",
    "    * determine evaluation layers\n",
    "    * fetch and merge gdfs for given muni (if they exist)\n",
    "    * save to `input-for-bike-node-planner/X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "exec(open(\"../src/raw-to-processed.py\").read())\n",
    "\n",
    "# define helper function to clean data folders\n",
    "def remove_output_data(output_folders, remove_previous_output: bool = False, verbose: bool = False):\n",
    "\n",
    "    if remove_previous_output:\n",
    "        for f in output_folders:\n",
    "            if os.path.exists(f):\n",
    "                shutil.rmtree(f)\n",
    "\n",
    "                os.makedirs(f)\n",
    "    if verbose:\n",
    "        print(\"Data folder cleaned!\")\n",
    "\n",
    "print(\"Libraries and functions imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Import configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config files\n",
    "config = yaml.load(\n",
    "    open(\"../config.yml\"), \n",
    "    Loader=yaml.FullLoader)\n",
    "proj_crs = config[\"proj_crs\"]\n",
    "wfs_version = config[\"geofa_wfs_version\"]\n",
    "node_layer_name = config[\"geofa_nodes_layer_name\"]\n",
    "stretches_layer_name = config[\"geofa_stretches_layer_name\"]\n",
    "\n",
    "municipalities = yaml.load(\n",
    "    open(\"../config-municipalities.yml\"), \n",
    "    Loader=yaml.FullLoader)\n",
    "codes = municipalities[\"kommunekode\"]\n",
    "\n",
    "geomtypes = [\"point\", \"linestring\", \"polygon\"]\n",
    "config_layers = {}\n",
    "for geomtype in geomtypes:\n",
    "    config_layers[geomtype] = yaml.load(\n",
    "        open(f\"../config-layers-{geomtype}.yml\"), \n",
    "        Loader=yaml.FullLoader)\n",
    "    \n",
    "print(\"Configurations imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Create subfolders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make folders\n",
    "main_folder = \"../input-for-bike-node-planner/\"\n",
    "os.makedirs(main_folder, exist_ok=True)\n",
    "\n",
    "sub_folders = [\n",
    "    \"dem\",\n",
    "    \"elevation\",\n",
    "    \"linestring\",\n",
    "    \"network\",\n",
    "    \"point\",\n",
    "    \"polygon\",\n",
    "    \"studyarea\"\n",
    "]\n",
    "\n",
    "for sub_folder in sub_folders:\n",
    "    os.makedirs(main_folder + sub_folder, exist_ok=True)\n",
    "\n",
    "print(\"Subfolders created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Clean data folder**\n",
    "\n",
    "Removing old data (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove previous output\n",
    "remove_output_data(\n",
    "    [\n",
    "        \"../input-for-bike-node-planner/dem\",\n",
    "        \"../input-for-bike-node-planner/elevation\",\n",
    "        \"../input-for-bike-node-planner/linestring/\",\n",
    "        \"../input-for-bike-node-planner/network/\",\n",
    "        \"../input-for-bike-node-planner/point/\",\n",
    "        \"../input-for-bike-node-planner/polygon/\",\n",
    "        \"../input-for-bike-node-planner/studyarea/\"        \n",
    "    ],\n",
    "    remove_previous_output=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Create study area polygon**\n",
    "\n",
    "(based on municipality boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in municipality boundaries & create study area polygon\n",
    "gdf = gpd.read_file(\"../data/municipality-boundaries/municipality-boundaries.gpkg\")\n",
    "gdf = gdf.to_crs(proj_crs) # make sure we have the right projected CRS\n",
    "gdf = gdf[gdf[\"kommunekode\"].isin(codes)] # filter to municipality codes indicated in config file\n",
    "gdf_studyarea = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"geometry\": [gdf.unary_union]\n",
    "    },\n",
    "    crs = proj_crs\n",
    ")\n",
    "gdf_studyarea.to_file(\n",
    "    filename = \"../input-for-bike-node-planner/studyarea/studyarea.gpkg\", \n",
    "    index = False)\n",
    "print(\"Study area polygon created!\")\n",
    "#del gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Fetch and save raw network data from GeoFA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch input data from GeoFA (raw data)\n",
    "\n",
    "url = f\"https://geofa.geodanmark.dk/ows/fkg/fkg/?request=GetFeature&typename={node_layer_name}&service=WFS&version={wfs_version}\"\n",
    "\n",
    "knudepunkter = gpd.read_file(url)\n",
    "\n",
    "url = f\"https://geofa.geodanmark.dk/ows/fkg/fkg/?request=GetFeature&typename={stretches_layer_name}&service=WFS&version={wfs_version}\"\n",
    "\n",
    "straekninger = gpd.read_file(url)\n",
    "\n",
    "assert len(knudepunkter) > 0, \"No nodes found\"\n",
    "assert len(straekninger) > 0, \"No stretches found\"\n",
    "\n",
    "# limit to extent of study area\n",
    "assert straekninger.crs == gdf_studyarea.crs\n",
    "assert knudepunkter.crs == gdf_studyarea.crs\n",
    "\n",
    "edges_studyarea = straekninger.sjoin(gdf_studyarea, predicate=\"intersects\").copy()\n",
    "edges_studyarea.drop(columns=[\"index_right\"], inplace=True)\n",
    "nodes_studyarea = knudepunkter.clip(edges_studyarea.buffer(500).unary_union)\n",
    "\n",
    "# remove empty geometries\n",
    "edges_studyarea = edges_studyarea[edges_studyarea.geometry.notna()].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "nodes_studyarea = nodes_studyarea[nodes_studyarea.geometry.notna()].reset_index(\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "# assert there is one (and only one) LineString per edge geometry row\n",
    "nodes_studyarea = nodes_studyarea.explode(index_parts=False).reset_index(drop=True)\n",
    "assert all(nodes_studyarea.geometry.type == \"Point\")\n",
    "assert all(nodes_studyarea.geometry.is_valid)\n",
    "\n",
    "# assert there is one (and only one) Point per node geometry row\n",
    "edges_studyarea = edges_studyarea.explode(index_parts=False).reset_index(drop=True)\n",
    "assert all(edges_studyarea.geometry.type == \"LineString\")\n",
    "assert all(edges_studyarea.geometry.is_valid)\n",
    "\n",
    "# save\n",
    "os.makedirs(\n",
    "    \"../input-for-bike-node-planner/network/raw/\", \n",
    "    exist_ok = True\n",
    ")\n",
    "\n",
    "edges_studyarea.to_file(\n",
    "    \"../input-for-bike-node-planner/network/raw/edges.gpkg\", index=False\n",
    ")\n",
    "\n",
    "nodes_studyarea.to_file(\n",
    "    \"../input-for-bike-node-planner/network/raw/nodes.gpkg\", index=False\n",
    ")\n",
    "\n",
    "print(\"Raw data on nodes and edges for study area fetched and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Process (clean) and save network data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_studyarea[\"edge_id\"] = edges_studyarea.id_cykelknudepunktsstraekning\n",
    "assert len(edges_studyarea) == len(edges_studyarea[\"edge_id\"].unique())\n",
    "\n",
    "nodes_studyarea[\"node_id\"] = nodes_studyarea.id_cykelknudepkt\n",
    "assert len(nodes_studyarea) == len(nodes_studyarea[\"node_id\"].unique())\n",
    "\n",
    "processed_edges = assign_edges_start_end_nodes(edges_studyarea, nodes_studyarea)\n",
    "\n",
    "processed_edges = order_edge_nodes(processed_edges)\n",
    "\n",
    "processed_edges = find_parallel_edges(processed_edges)\n",
    "\n",
    "assert len(processed_edges) == len(edges_studyarea)\n",
    "\n",
    "processed_nodes = nodes_studyarea.loc[\n",
    "    nodes_studyarea[\"node_id\"].isin(processed_edges[\"u\"])\n",
    "    | nodes_studyarea[\"node_id\"].isin(processed_edges[\"v\"])\n",
    "]\n",
    "\n",
    "# save to files\n",
    "os.makedirs(\n",
    "    \"../input-for-bike-node-planner/network/processed/\",\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "processed_nodes.to_file(\n",
    "    \"../input-for-bike-node-planner/network/processed/nodes.gpkg\", index=False\n",
    ")\n",
    "\n",
    "processed_edges.to_file(\n",
    "    \"../input-for-bike-node-planner/network/processed/edges.gpkg\", index=False\n",
    ")\n",
    "\n",
    "print(\"Data on nodes and edges for study area processed and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Generate evaluation layers (point, linestring, polygon)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of evaluation layers (based on config file inputs)\n",
    "\n",
    "layer_dict = {}\n",
    "\n",
    "for geomtype in geomtypes:\n",
    "\n",
    "    layer_dict[geomtype] = {}\n",
    "\n",
    "    # determine evaluation layers\n",
    "    layers = []\n",
    "    for v in config_layers[geomtype].values():\n",
    "        layers += list(set(v.values()))\n",
    "    layers = list(set(layers))\n",
    "    \n",
    "    # determine data sets that go into each layer\n",
    "\n",
    "    # key is name of merged output layer, value is a dict \n",
    "    for layer in layers:\n",
    "        layer_dict[geomtype][layer] = {}\n",
    "    \n",
    "    # adding data source as key to dictindict IF relevant to layer\n",
    "    for datasource, vdict in config_layers[geomtype].items():\n",
    "        for layer in (set(vdict.values())):\n",
    "            layer_dict[geomtype][layer][datasource] = []\n",
    "    \n",
    "    for datasource, vdict in config_layers[geomtype].items():\n",
    "        for k, v in vdict.items():\n",
    "            layer_dict[geomtype][v][datasource] += [k]\n",
    "\n",
    "for geomtype in geomtypes:\n",
    "    if \"ignore\" in layer_dict[geomtype]:\n",
    "        del layer_dict[geomtype][\"ignore\"]\n",
    "\n",
    "# for each layer type (point/linestring/polygon),\n",
    "\n",
    "print(\"Generation of evaluation layers started\")\n",
    "\n",
    "for geomtype in geomtypes:\n",
    "    \n",
    "    # go through all evaluation layers for that geomtype... \n",
    "    for layername, datadict in layer_dict[geomtype].items():\n",
    "    \n",
    "        final_gdf = gpd.GeoDataFrame()\n",
    "        \n",
    "        # go through each data source for that evaluation layer...\n",
    "        for k, v in datadict.items():\n",
    "\n",
    "            gdf = gpd.GeoDataFrame()\n",
    "\n",
    "            # and fetch it for each municipality\n",
    "            for code in codes:\n",
    "                # for each code, check if file exists, if yes: read it in, if not empty: concatenate\n",
    "                fp = f\"../data/{geomtype}/{code}/{k}.gpkg\"\n",
    "                if os.path.exists(fp):\n",
    "                    gdf_muni = gpd.read_file(fp)\n",
    "                    if not gdf_muni.empty:\n",
    "                        gdf = pd.concat(\n",
    "                            [\n",
    "                                gdf,\n",
    "                                gdf_muni\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "            # if at least one of the municipalities has data from this data source,\n",
    "            # add it to final gdf\n",
    "            if not gdf.empty:\n",
    "                final_gdf = pd.concat(\n",
    "                    [\n",
    "                        final_gdf,\n",
    "                        gdf[gdf[\"type\"].isin(v)]\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        # save evaluation layer to file, if not empty\n",
    "        if not final_gdf.empty:\n",
    "            final_gdf = final_gdf.reset_index(drop=True)\n",
    "            final_gdf.to_file(\n",
    "                f\"../input-for-bike-node-planner/{geomtype}/{layername}.gpkg\", \n",
    "                index = False\n",
    "            )\n",
    "            print(\"\\t \\t\", f\"{layername} layer saved\")\n",
    "        else:\n",
    "            print(\"\\t \\t\", f\"No data found for {layername} layer\")\n",
    "    \n",
    "print(\"Generation of evaluation layers ended successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Download and merge elevation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_output_data(\n",
    "    [\n",
    "        \"../data/dem\", \n",
    "        \"../input-for-bike-node-planner/dem\"\n",
    "    ], \n",
    "    remove_previous_output=True\n",
    ")\n",
    "\n",
    "print(\"Downloading and merging elevation data. This can take up to several minutes per municipality.\")\n",
    "\n",
    "exec(open(\"../src/dem-download.py\").read())\n",
    "\n",
    "print(\"\\t Elevation data downloaded!\")\n",
    "print(\"\\t Merging data...\")\n",
    "\n",
    "exec(open(\"../src/dem-merge.py\").read())\n",
    "\n",
    "print(\"Elevation data ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**All done!**\n",
    "\n",
    "All done! Now you can copy-paste all subfolders of `/input-for-bike-node-planner/` into the `/data/input/` folder of `bike-node-planner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All done! Now you can copy-paste \\nall subfolders of '/input-for-bike-node-planner/' \\ninto the '/data/input/' folder of bike-node-planner\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
